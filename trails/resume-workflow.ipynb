{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume_Workflow - essential cells to run after restarting VS Code / kernel\n",
    "# Kernel: use your `niva-notebook` kernel\n",
    "\n",
    "# %%\n",
    "# Cell 1 - load env, basic imports and connections\n",
    "from dotenv import load_dotenv\n",
    "import os, json\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX = os.getenv(\"PINECONE_INDEX\",\"medical-knowledge\")\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\",\"http://127.0.0.1:11434\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\",\"llama3\")\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\",\"./data/medical_knowledge.csv\")\n",
    "\n",
    "print(\"PINECONE_API_KEY set?\", bool(PINECONE_API_KEY))\n",
    "print(\"OLLAMA_URL:\", OLLAMA_URL)\n",
    "print(\"CSV_PATH exists?\", os.path.exists(CSV_PATH))\n",
    "\n",
    "# Initialize Pinecone client (if you use Pinecone)\n",
    "try:\n",
    "    from pinecone import Pinecone\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(PINECONE_INDEX)\n",
    "    print(\"Connected to Pinecone index:\", PINECONE_INDEX)\n",
    "except Exception as e:\n",
    "    print(\"Pinecone init failed (ok if not using now):\", e)\n",
    "\n",
    "# Load embedding model (SentenceTransformers)\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    print(\"Embedding model ready. Dim:\", len(embed_model.encode(\"test\")))\n",
    "except Exception as e:\n",
    "    print(\"Embedding model load failed:\", e)\n",
    "\n",
    "# %%\n",
    "# Cell 2 - robust call_ollama() that handles NDJSON streaming\n",
    "import requests, re\n",
    "\n",
    "essential_ollama_url = OLLAMA_URL.rstrip('/') + '/api/generate'\n",
    "\n",
    "def call_ollama(prompt, max_tokens=500, temperature=0.0, timeout=60):\n",
    "    payload = {\"model\": MODEL_NAME, \"prompt\": prompt, \"max_tokens\": max_tokens, \"temperature\": temperature, \"stream\": False}\n",
    "    try:\n",
    "        r = requests.post(essential_ollama_url, json=payload, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Ollama request failed: {e}\")\n",
    "\n",
    "    text = (r.text or \"\").strip()\n",
    "    # try single json\n",
    "    try:\n",
    "        data = r.json()\n",
    "        if isinstance(data, dict):\n",
    "            if \"response\" in data:\n",
    "                return data[\"response\"]\n",
    "            if \"output\" in data:\n",
    "                return data[\"output\"]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # NDJSON fallback: parse line-by-line, concatenate 'response' fields\n",
    "    out = \"\"\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            if isinstance(obj, dict) and obj.get(\"response\"):\n",
    "                out += str(obj.get(\"response\"))\n",
    "        except Exception:\n",
    "            # ignore non-json lines\n",
    "            continue\n",
    "    return out.strip()\n",
    "\n",
    "print(\"call_ollama ready\")\n",
    "\n",
    "# %%\n",
    "# Cell 3 - next_question_rag() using embed_model + Pinecone index\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def next_question_rag(user_text, k=3):\n",
    "    # require embed_model and index to be defined\n",
    "    try:\n",
    "        qvec = embed_model.encode(user_text).tolist()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Embedding failed: {e}\")\n",
    "\n",
    "    try:\n",
    "        res = index.query(vector=qvec, top_k=k, include_metadata=True)\n",
    "        ctx_text = \"\\n\\n\".join([m['metadata'].get('text','') for m in res.get('matches',[])])\n",
    "    except Exception as e:\n",
    "        ctx_text = \"\"\n",
    "        print(\"Pinecone query failed (context empty):\", e)\n",
    "\n",
    "    prompt = f\"You are a concise medical triage assistant. Use ONLY the context below to ask ONE concise follow-up question that helps clarify the patient's symptom described.\\n\\nContext:\\n{ctx_text}\\n\\nPatient statement:\\n{user_text}\\n\\nAsk only the next question.\"\n",
    "    return call_ollama(prompt, max_tokens=200)\n",
    "\n",
    "print(\"next_question_rag ready\")\n",
    "\n",
    "# %%\n",
    "# Cell 4 - load or create chat_history (required by extraction)\n",
    "# Option A: load previously saved chat report\n",
    "report_path = os.path.join(\"outputs\",\"report.json\")\n",
    "chat_history = None\n",
    "if os.path.exists(report_path):\n",
    "    try:\n",
    "        with open(report_path,'r',encoding='utf-8') as f:\n",
    "            saved = json.load(f)\n",
    "            chat_history = saved.get('chat_history') or saved.get('transcript')\n",
    "            print('Loaded chat_history from outputs/report.json')\n",
    "    except Exception as e:\n",
    "        print('Failed to load saved report:', e)\n",
    "\n",
    "# Option B: if not available, create a small sample transcript\n",
    "if not chat_history:\n",
    "    chat_history = (\n",
    "        \"Patient: I have had chest pain and mild breathlessness since morning.\\n\"\n",
    "        \"Bot: When did the pain start and does it radiate anywhere?\\n\"\n",
    "        \"Patient: The pain is sharp and increases on deep breathing. I also feel dizzy.\\n\"\n",
    "    )\n",
    "    print('Using sample chat_history')\n",
    "\n",
    "print('chat_history length:', len(chat_history))\n",
    "\n",
    "# %%\n",
    "# Cell 5 - extraction: ask LLM to return ONLY JSON and robustly parse\n",
    "import re\n",
    "\n",
    "schema_instr = (\n",
    "    'Output ONLY a single valid JSON object with keys:\\n'\n",
    "    '- symptoms: list of strings\\n'\n",
    "    '- duration: string\\n'\n",
    "    '- severity: string (mild/moderate/severe)\\n'\n",
    "    '- medications: list\\n'\n",
    "    '- allergies: list\\n'\n",
    "    '- urgency: string (low/medium/high)\\n'\n",
    "    'Do not output any extra text.'\n",
    ")\n",
    "\n",
    "prompt = f\"{schema_instr}\\n\\nConversation:\\n{chat_history}\\n\\nNow output ONLY the JSON.\"\n",
    "raw = call_ollama(prompt, max_tokens=600)\n",
    "print('Raw model output (preview):', raw[:600])\n",
    "\n",
    "# robust JSON extraction\n",
    "m = re.search(r'(\\{.*\\})', raw, re.S)\n",
    "structured = {}\n",
    "if m:\n",
    "    try:\n",
    "        structured = json.loads(m.group(1))\n",
    "        print('Structured parsed successfully')\n",
    "    except Exception as e:\n",
    "        print('JSON parse failed:', e)\n",
    "else:\n",
    "    print('No JSON object found in model output')\n",
    "\n",
    "print('Structured keys:', list(structured.keys()))\n",
    "\n",
    "# %%\n",
    "# Cell 6 - triage and save result\n",
    "def triage_report(s):\n",
    "    if not s: return {'specialist':'General Physician','urgency':'low'}\n",
    "    symptoms = ' '.join(s.get('symptoms',[])).lower()\n",
    "    if any(w in symptoms for w in ['chest','breath','shortness','palpit']):\n",
    "        return {'specialist':'Cardiology/Emergency','urgency':'high'}\n",
    "    if any(w in symptoms for w in ['rash','itch','lesion']):\n",
    "        return {'specialist':'Dermatology','urgency':'medium'}\n",
    "    if any(w in symptoms for w in ['headache','dizzy','seizure']):\n",
    "        return {'specialist':'Neurology','urgency':'medium'}\n",
    "    return {'specialist':'General Physician','urgency':'low'}\n",
    "\n",
    "triage = triage_report(structured)\n",
    "print('Triage result:', triage)\n",
    "\n",
    "# save\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "out = {'chat_history': chat_history, 'structured': structured, 'triage': triage}\n",
    "with open('outputs/resume_report.json','w',encoding='utf-8') as f:\n",
    "    json.dump(out,f,indent=2)\n",
    "print('Saved outputs/resume_report.json')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
